import os
import time
import random
import traceback
import subprocess
import numpy as np
import torch.multiprocessing as mp
from multiprocessing import Pool
from tqdm import tqdm
from utiles import load_dataset_Vstar_json
from inference import cycle_epoch_infer

# --- ğŸ”¥ æ–°å¢ï¼šå­è¿›ç¨‹ä¿æŠ¤å£³å‡½æ•° ---
def worker_wrapper(func, *args, **kwargs):
    try:
        return func(*args, **kwargs)
    except Exception as e:
        print(f"\nâŒ [å­è¿›ç¨‹æŠ¥é”™] æ•è·åˆ°å¼‚å¸¸: {e}")
        print("="*60)
        traceback.print_exc()
        print("="*60)
        raise e

def get_available_gpus(max_memory_mb=1000, max_gpus=None):
    """è·å–å¯ç”¨GPUåˆ—è¡¨ (å·²åŒ…å«å±è”½0å·å¡é€»è¾‘)"""
    try:
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=memory.used', '--format=csv,noheader,nounits'],
            capture_output=True, text=True, check=True
        )
        used_memory = [int(x.strip()) for x in result.stdout.strip().split('\n')]
        gpu_memory_pairs = [(i, mem) for i, mem in enumerate(used_memory)]
        gpu_memory_pairs.sort(key=lambda x: x[1])
        # å±è”½ 0 å·å¡
        available_gpus = [gpu_id for gpu_id, mem in gpu_memory_pairs if mem < max_memory_mb and gpu_id != 0]
        if max_gpus is not None:
            available_gpus = available_gpus[:max_gpus]
        return available_gpus
    except Exception as e:
        print(f"Error detecting GPU memory: {e}")
        return []

def main(datasetdir, savedir, max_pixels, Parallels, sig, thre, head_config_path, para_nums=6):
    # è®¾ç½®ç¯å¢ƒå˜é‡
    if head_config_path:
        if os.path.exists(head_config_path):
            os.environ["HEAD_CONFIG_PATH"] = head_config_path
            print(f"ğŸ”§ [Config] Head é…ç½®æ–‡ä»¶è·¯å¾„: {head_config_path}")
        else:
            print(f"âš ï¸ [Warning] Head é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {head_config_path}")
            # å¦‚æœé…ç½®æ–‡ä»¶å¿…é¡»å­˜åœ¨æ‰èƒ½è·‘ï¼Œè¿™é‡Œå»ºè®®ç›´æ¥ returnï¼Œé˜²æ­¢è·‘å‡ºé”™è¯¯ç»“æœ
            return 

    if not Parallels: para_nums = 1
    
    # åŠ è½½æ•°æ®é›†
    dataset = load_dataset_Vstar_json(datasetdir)
    random.shuffle(dataset)
    
    available_gpus = get_available_gpus(max_memory_mb=1000, max_gpus=para_nums)
    if len(available_gpus) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç©ºé—² GPU")
        return
        
    print(f"âœ… æ‰¾åˆ° {len(available_gpus)} ä¸ªå¯ç”¨ GPU: {available_gpus}")
    
    splits = np.array_split(dataset, len(available_gpus))
    print("æ–‡ä»¶åŠ è½½å®Œæˆ")
    
    if not Parallels:
        for rank, gpu_id in tqdm(enumerate(available_gpus)):
            dataset_part = splits[rank]
            cycle_epoch_infer(gpu_id, rank, dataset_part, savedir, max_pixels, sig, thre)
    else:
        pool = Pool(processes=len(available_gpus))
        results = []
        for rank, gpu_id in tqdm(enumerate(available_gpus)):
            dataset_part = splits[rank]
            res = pool.apply_async(
                worker_wrapper,
                args=(cycle_epoch_infer, gpu_id, rank, dataset_part, savedir, max_pixels, sig, thre),
                error_callback=lambda e: print(f"âš ï¸ ä¸»è¿›ç¨‹æ„ŸçŸ¥åˆ°å­è¿›ç¨‹é”™è¯¯: {e}") 
            )
            results.append(res)
        
        pool.close()
        for res in tqdm(results, desc="ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ"):
            res.wait()
        pool.join()

if __name__ == "__main__":
    mp.set_start_method('spawn', force=True)
    
    # å›ºå®šå‚æ•°è®¾ç½®
    maxp = 16384
    Parallels = True
    sigma = [3]
    threshold = [0.7]
    seed = 2077
    #datasetdir = f"/data2/shaos/data/vstar_bench/test_questions_converted.json"
    datasetdir = f"/data2/shaos/data/vstar_bench/relative_position_154.jsonl"
    # ğŸ”¥ğŸ”¥ğŸ”¥ å¾ªç¯è¿è¡Œ 1 åˆ° 100 ğŸ”¥ğŸ”¥ğŸ”¥

    print(f"\n{'#'*30}")
    print(f"ğŸš€ å¼€å§‹è¿è¡Œ: Top Heads")
    print(f"{'#'*30}\n")
    
    # 1. åŠ¨æ€è®¾ç½® Head Config è·¯å¾„
    head_config_jsonl = f"/data2/shaos/labs/mllms_know_94.1_head_select/head_analysisi/head_analysis_results/All_Samples_top_6_heads_by_ratio_L0_to_L27.jsonl"
    
    # 2. åŠ¨æ€è®¾ç½®ä¿å­˜è·¯å¾„ (é˜²æ­¢è¦†ç›–)
    # æ³¨æ„ï¼šæˆ‘ä¹ŸæŠŠè¾“å‡ºæ–‡ä»¶åæ”¹æˆäº† ...top_{n}_heads.json
    savejson = f"vstar_results_1confidence_prompt_easy_all_step_answer_save_top_6_heads.json"
    
    # 3. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œé¿å…æŠ¥é”™
    if not os.path.exists(head_config_jsonl):
        print(f"âŒ è·³è¿‡: é…ç½®æ–‡ä»¶æœªæ‰¾åˆ° -> {head_config_jsonl}")

    try:
        # æ¯æ¬¡å¾ªç¯é‡ç½®éšæœºç§å­ï¼Œç¡®ä¿é™¤Headå¤–å…¶ä»–æ¡ä»¶ä¸€è‡´
        random.seed(seed)
        
        # æ‰§è¡Œä¸»å‡½æ•°
        main(datasetdir, savejson, maxp, Parallels, sigma, threshold, head_config_jsonl, 4)
        
        print(f"âœ… å®Œæˆ: Top 6 Heads -> ç»“æœå·²ä¿å­˜è‡³ {savejson}")
        
    except Exception as e:
        print(f"âŒ è¿è¡Œ Top 6æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()
    
    # å¯é€‰ï¼šç¨ä½œåœé¡¿è®©æ˜¾å­˜ç¨å¾®é‡Šæ”¾ä¸€ä¸‹ï¼Œè™½ç„¶ spawn æ¨¡å¼ä¸‹å­è¿›ç¨‹ç»“æŸä¼šè‡ªåŠ¨é‡Šæ”¾
    time.sleep(2)

    print("\nğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰ 1-100 ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼")