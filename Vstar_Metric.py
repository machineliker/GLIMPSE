import json
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict
import matplotlib

# è®¾ç½®æ— å¤´æ¨¡å¼ï¼Œé˜²æ­¢åœ¨ Linux æœåŠ¡å™¨æ— æ˜¾ç¤ºå™¨ç¯å¢ƒä¸‹æŠ¥é”™
matplotlib.use('Agg') 

# ==========================================
# 1. åŸºç¡€å·¥å…·æ¨¡å—
# ==========================================

def read_multi_line_json_objects(file_path):
    """
    è¯»å–å¯èƒ½åŒ…å«æ ¼å¼é”™è¯¯çš„ JSONL æ–‡ä»¶ (Robust Reader)
    """
    data = []
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return []
        
    print(f"ğŸ“‚ æ­£åœ¨è¯»å–æ–‡ä»¶: {os.path.basename(file_path)} ...")
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read().strip()
        # ä¿®å¤è¿åœ¨ä¸€èµ·çš„ JSON å¯¹è±¡ (ä¾‹å¦‚ '}\n{')
        objects = content.replace('}\n{', '}|-|-|{').split('|-|-|')
        
        for obj_str in objects:
            if not obj_str.strip(): continue
            try:
                parsed_obj = json.loads(obj_str)
                # è¿‡æ»¤æ‰éå­—å…¸ç±»å‹çš„è„æ•°æ®
                if isinstance(parsed_obj, dict):
                    data.append(parsed_obj)
            except: pass 
            
    print(f"âœ… æˆåŠŸåŠ è½½ {len(data)} æ¡æœ‰æ•ˆæ ·æœ¬")
    return data

def normalize_answer(ans):
    """æ ‡å‡†åŒ–ç­”æ¡ˆæ ¼å¼ (å¤„ç† list æˆ– str, ç»Ÿä¸€è½¬å¤§å†™)"""
    if isinstance(ans, list): 
        ans = ans[-1]
    return str(ans).strip().upper()

def get_method_key(data):
    """è‡ªåŠ¨æ£€æµ‹æ•°æ®ä¸­çš„ä¸»è¦ Key (å¦‚ HiDe_s3_t0.7)"""
    for item in data:
        if "step_answers" in item:
            keys = list(item["step_answers"].keys())
            if keys: return keys[0]
    return None

# ==========================================
# 2. æ ¸å¿ƒåˆ†ææ¨¡å—
# ==========================================

def get_accuracy_at_specific_threshold(data, method_key, target_threshold):
    """
    åŠŸèƒ½ï¼šè¾“å…¥ä¸€ä¸ªç½®ä¿¡åº¦é˜ˆå€¼ï¼Œè¿”å›è¯¥è®¾ç½®ä¸‹çš„å‡†ç¡®ç‡è¯¦æƒ…ã€‚
    """
    print("\n" + "="*80)
    print(f"ğŸ¯ æŸ¥è¯¢ç‰¹å®šé˜ˆå€¼è¡¨ç° (Target Threshold: {target_threshold})")
    print("="*80)
    
    samples = [d for d in data if "step_answers" in d and method_key in d["step_answers"]]
    total = len(samples)
    
    if total == 0:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆæ ·æœ¬ã€‚")
        return

    correct_last = 0
    correct_max = 0
    early_exit_count = 0  # ç»Ÿè®¡æœ‰å¤šå°‘æ ·æœ¬è§¦å‘äº†æ—©åœ

    for item in samples:
        gt = normalize_answer(item["Ground truth"])
        ans_list = item["step_answers"][method_key]
        conf_list = item["confidence_history"][method_key]
        
        # æ¨¡æ‹Ÿæ—©åœé€»è¾‘
        hit = False
        curr_ans = None
        
        for i, conf in enumerate(conf_list):
            if conf >= target_threshold:
                hit = True
                curr_ans = normalize_answer(ans_list[i])
                break
        
        if hit:
            early_exit_count += 1
            # è§¦å‘æ—©åœæ—¶ï¼Œä¸¤ç§ç­–ç•¥ç»“æœä¸€æ ·
            pred_last = curr_ans
            pred_max = curr_ans
        else:
            # æœªè§¦å‘æ—©åœï¼Œè¿›å…¥ä¿åº•é€»è¾‘
            pred_last = normalize_answer(ans_list[-1]) # ç­–ç•¥ A: åšæŒåˆ°åº•
            pred_max = normalize_answer(ans_list[np.argmax(conf_list)]) # ç­–ç•¥ B: å›æº¯æœ€é«˜ç½®ä¿¡åº¦
        
        if pred_last == gt: correct_last += 1
        if pred_max == gt: correct_max += 1

    acc_last = correct_last / total
    acc_max = correct_max / total
    exit_rate = early_exit_count / total

    print(f"ğŸ“Š æ ·æœ¬æ€»æ•°: {total}")
    print(f"âš¡ æ—©åœè§¦å‘ç‡ (Early Exit Rate): {exit_rate:.2%} (å³ {early_exit_count} ä¸ªæ ·æœ¬åœ¨ç½®ä¿¡åº¦ >= {target_threshold} æ—¶åœæ­¢)")
    print("-" * 65)
    print(f"{'Strategy (ä¿åº•ç­–ç•¥)':<30} | {'Accuracy (å‡†ç¡®ç‡)':<20}")
    print("-" * 65)
    print(f"{'Fallback: Last Step (æœ€åä¸€æ­¥)':<30} | {acc_last:.2%} ({correct_last}/{total})")
    print(f"{'Fallback: Max Conf  (æœ€é«˜ç½®ä¿¡åº¦)':<30} | {acc_max:.2%} ({correct_max}/{total})")
    print("-" * 65)
    
    return acc_last, acc_max

def analyze_optimal_threshold_curve(data, method_key):
    """
    åŠŸèƒ½ï¼šéå† 0-1 çš„æ‰€æœ‰é˜ˆå€¼ï¼Œå¯»æ‰¾æœ€ä½³ç‚¹å¹¶ç”»å›¾
    """
    print("\n" + "="*80)
    print("ğŸ“ˆ åˆ†æ: æœ€ä½³ç½®ä¿¡åº¦é˜ˆå€¼æœç´¢ (Global Search)")
    print("="*80)
    
    samples = [d for d in data if "step_answers" in d and method_key in d["step_answers"]]
    thresholds = np.linspace(0, 1.0, 101)
    acc_last = []
    acc_max = []

    for t in thresholds:
        c_last = 0
        c_max = 0
        total = len(samples)
        
        for item in samples:
            gt = normalize_answer(item["Ground truth"])
            ans_list = item["step_answers"][method_key]
            conf_list = item["confidence_history"][method_key]
            
            # æ¨¡æ‹Ÿæ—©åœ
            hit = False
            curr_ans = None
            for i, conf in enumerate(conf_list):
                if conf >= t:
                    hit = True
                    curr_ans = normalize_answer(ans_list[i])
                    break
            
            pred_last = curr_ans if hit else normalize_answer(ans_list[-1])
            pred_max = curr_ans if hit else normalize_answer(ans_list[np.argmax(conf_list)])
            
            if pred_last == gt: c_last += 1
            if pred_max == gt: c_max += 1
            
        acc_last.append(c_last / total)
        acc_max.append(c_max / total)
        
    best_idx_last = np.argmax(acc_last)
    best_idx_max = np.argmax(acc_max)
    
    print(f"ç­–ç•¥ A (Fallback Last) | æœ€ä½³é˜ˆå€¼: {thresholds[best_idx_last]:.2f} | æœ€é«˜å‡†ç¡®ç‡: {acc_last[best_idx_last]:.2%}")
    print(f"ç­–ç•¥ B (Fallback Max)  | æœ€ä½³é˜ˆå€¼: {thresholds[best_idx_max]:.2f} | æœ€é«˜å‡†ç¡®ç‡: {acc_max[best_idx_max]:.2%}")

    # ç”»å›¾
    plt.figure(figsize=(10, 6))
    plt.plot(thresholds, acc_last, label='Fallback: Last', color='blue', linewidth=2)
    plt.plot(thresholds, acc_max, label='Fallback: Max', color='red', linestyle='--', linewidth=2)
    
    # æ ‡è®°æœ€é«˜ç‚¹
    plt.scatter(thresholds[best_idx_last], acc_last[best_idx_last], c='blue', s=100, zorder=5)
    plt.scatter(thresholds[best_idx_max], acc_max[best_idx_max], c='red', s=100, zorder=5)
    
    plt.title(f'Accuracy vs Threshold ({method_key})')
    plt.xlabel('Confidence Threshold')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xlim(0, 1.05)
    
    save_name = 'accuracy_curve.png'
    plt.savefig(save_name, dpi=300)
    print(f"ğŸ–¼ï¸  æ›²çº¿å›¾å·²ä¿å­˜ä¸º: {save_name}")

def analyze_category_accuracy(data, method_key):
    """
    åŠŸèƒ½ï¼šæŒ‰ç±»åˆ«ç»Ÿè®¡ Ori, Last, MaxConf çš„å‡†ç¡®ç‡
    """
    print("\n" + "="*80)
    print("ğŸ“Š åˆ†æ: ä¸åŒç±»åˆ«çš„å‡†ç¡®ç‡ (Category Accuracy Table)")
    print("="*80)
    
    stats = defaultdict(lambda: defaultdict(lambda: {'correct': 0, 'total': 0}))
    strategies = ['Ori', 'Last', 'MaxConf']
    
    for item in data:
        if "step_answers" not in item or method_key not in item["step_answers"]:
            continue
            
        cat = item.get("category", item.get("Category", "Unknown"))
        gt = normalize_answer(item["Ground truth"])
        
        ans_list = item["step_answers"][method_key]
        conf_list = item["confidence_history"][method_key]
        
        preds = {}
        preds['Ori'] = normalize_answer(item["answer"].get("ori", "INVALID"))
        preds['Last'] = normalize_answer(ans_list[-1])
        preds['MaxConf'] = normalize_answer(ans_list[np.argmax(conf_list)])
        
        for strat in strategies:
            stats[cat][strat]['total'] += 1
            stats['Overall'][strat]['total'] += 1 
            if preds[strat] == gt:
                stats[cat][strat]['correct'] += 1
                stats['Overall'][strat]['correct'] += 1

    rows = []
    sorted_cats = sorted([c for c in stats.keys() if c != 'Overall']) + ['Overall']
    
    for cat in sorted_cats:
        row = {'Category': cat}
        for strat in strategies:
            c = stats[cat][strat]['correct']
            t = stats[cat][strat]['total']
            acc = c / t if t > 0 else 0
            # æ ¼å¼: 85.00% (17/20)
            row[f'{strat}'] = f"{acc:.2%} ({c}/{t})"
        rows.append(row)
        
    df = pd.DataFrame(rows)
    # æ‰“å°è¡¨æ ¼
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', 1000)
    pd.set_option('display.max_colwidth', 30)
    print(df.to_string(index=False))

def export_error_samples(data, method_key, target_strategy='MaxConf'):
    """
    åŠŸèƒ½ï¼šå¯¼å‡ºé¢„æµ‹é”™è¯¯çš„æ ·æœ¬ ID
    """
    print("\n" + "="*80)
    print(f"ğŸ“‹ åˆ†æ: æå–é”™è¯¯æ ·æœ¬ ID (Strategy: {target_strategy})")
    print("="*80)
    
    error_ids = []
    for item in data:
        if "step_answers" not in item or method_key not in item["step_answers"]:
            continue
            
        sample_id = item.get("id", "unknown")
        gt = normalize_answer(item["Ground truth"])
        ans_list = item["step_answers"][method_key]
        conf_list = item["confidence_history"][method_key]
        
        pred = ""
        if target_strategy == 'Last':
            pred = normalize_answer(ans_list[-1])
        elif target_strategy == 'MaxConf':
            max_idx = np.argmax(conf_list)
            pred = normalize_answer(ans_list[max_idx])
        elif target_strategy == 'Ori':
             pred = normalize_answer(item["answer"].get("ori", ""))
             
        if pred != gt:
            error_ids.append(str(sample_id))
            
    filename = f"error_ids_{target_strategy}.txt"
    with open(filename, "w") as f:
        f.write("\n".join(error_ids))
        
    print(f"å‘ç° {len(error_ids)} ä¸ªé”™è¯¯æ ·æœ¬ã€‚å‰10ä¸ªID: {error_ids[:10]}")
    print(f"ğŸ’¾ å·²ä¿å­˜è‡³: {filename}")

# ==========================================
# ä¸»æ‰§è¡Œå…¥å£
# ==========================================

if __name__ == "__main__":
    # ğŸ”´ è®¾ç½®ï¼šJSONL æ–‡ä»¶è·¯å¾„
    file_path = r"/data1/shaos/labs/HiDe_3/data1/shaos/labs/HiDe/Hide/HR_8k_results_1confidence_prompt_easy_all_step_answer_save_top_6_heads.json"
    
    # ğŸ”´ è®¾ç½®ï¼šä½ æƒ³æŸ¥è¯¢çš„å…·ä½“é˜ˆå€¼
    my_target_threshold = 0.95

    # è¯»å–æ•°æ®
    data = read_multi_line_json_objects(file_path)
    
    if data:
        # 1. è‡ªåŠ¨è·å–ä¸» Key (e.g. HiDe_s3_t0.7)
        key = get_method_key(data)
        
        if key:
            print(f"ğŸ” æ£€æµ‹åˆ°æ–¹æ³• Key: {key}")
            
            # åŠŸèƒ½ 1: æŸ¥è¯¢æŒ‡å®šé˜ˆå€¼ä¸‹çš„å‡†ç¡®ç‡
            get_accuracy_at_specific_threshold(data, key, my_target_threshold)
            
            # åŠŸèƒ½ 2: ç»˜åˆ¶æœ€ä½³é˜ˆå€¼æ›²çº¿ (ç”Ÿæˆ accuracy_curve.png)
            analyze_optimal_threshold_curve(data, key)
            
            # åŠŸèƒ½ 3: æ‰“å°åˆ†ç±»åˆ«å‡†ç¡®ç‡è¡¨æ ¼
            analyze_category_accuracy(data, key)
            
            # åŠŸèƒ½ 4: å¯¼å‡ºé”™è¯¯æ ·æœ¬ ID (é»˜è®¤å¯¼å‡º MaxConf ç­–ç•¥ä¸‹çš„é”™è¯¯)
            export_error_samples(data, key, target_strategy='MaxConf')
            
        else:
            print("âŒ æ•°æ®ä¸­æœªæ‰¾åˆ° 'step_answers' å­—æ®µï¼Œè¯·æ£€æŸ¥æ¨ç†ä»£ç æ˜¯å¦æ­£ç¡®ä¿å­˜äº†æ¯æ­¥ç»“æœã€‚")